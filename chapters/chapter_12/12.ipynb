{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66edfacb",
   "metadata": {},
   "source": [
    "## Визуализация аудио сигнала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04025d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Импорт библиотеки для работы с массивами и математическими операциями\n",
    "import matplotlib.pyplot as plt  # Импорт библиотеки для построения графиков\n",
    "from scipy.io import wavfile  # Импорт функции для чтения WAV файлов из библиотеки SciPy\n",
    "\n",
    "# Чтение WAV файла: функция возвращает частоту дискретизации и аудиосигнал\n",
    "sampling_freq, signal = wavfile.read('dataset/random_sound.wav')\n",
    "\n",
    "# Вывод информации о загруженном аудиосигнале\n",
    "print('\\nФорма сигнала:', signal.shape)  # Размерность массива (количество отсчетов, количество каналов)\n",
    "print('Тип данных:', signal.dtype)  # Тип данных массива (обычно int16 для 16-битного аудио)\n",
    "print('Продолжительность сигнала:', round(signal.shape[0] / float(sampling_freq), 2), 'в секундах')\n",
    "# Вычисление продолжительности: количество отсчетов / частоту дискретизации\n",
    "\n",
    "# Нормализация сигнала: приведение значений к диапазону [-1, 1] для 16-битного аудио\n",
    "# 2^15 = 32768 (максимальное значение для 16-битного знакового целого)\n",
    "signal = signal / np.power(2, 15)\n",
    "\n",
    "# Ограничение сигнала первыми 50 отсчетами для визуализации небольшого фрагмента\n",
    "signal = signal[:50]\n",
    "\n",
    "# Создание временной оси в миллисекундах для построения графика\n",
    "# np.arange(0, len(signal), 1) создает массив индексов от 0 до 49\n",
    "# Каждый индекс умножается на 1000/частоту дискретизации для перевода в миллисекунды\n",
    "time_axis = 1000 * np.arange(0, len(signal), 1) / float(sampling_freq)\n",
    "\n",
    "# Построение графика аудиосигнала\n",
    "plt.plot(time_axis, signal, color='black')  # Черный график амплитуды сигнала\n",
    "plt.xlabel('Время (милисекунды)')  # Подпись оси X\n",
    "plt.ylabel('Амплитуда')  # Подпись оси Y\n",
    "plt.title('Входной аудио сигнал')  # Заголовок графика\n",
    "plt.show()  # Отображение графика"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ade860",
   "metadata": {},
   "source": [
    "## Генерирование аудиосигналов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7dbef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Импорт библиотеки для работы с массивами и математических операций\n",
    "import matplotlib.pyplot as plt  # Импорт библиотеки для построения графиков\n",
    "from scipy.io.wavfile import write  # Импорт функции записи WAV файлов из библиотеки SciPy\n",
    "\n",
    "# Имя файла для сохранения сгенерированного аудио\n",
    "output_file = 'dataset/generated_audio.wav'\n",
    "\n",
    "# Параметры генерации аудиосигнала\n",
    "duration = 4  # Продолжительность сигнала в секундах\n",
    "sampling_freq = 44100  # Частота дискретизации (стандартная для аудио - 44.1 кГц)\n",
    "tone_freq = 784  # Частота тона в Гц (нота С5 в музыкальной нотации)\n",
    "min_val = -4 * np.pi  # Минимальное значение для временной оси (в радианах)\n",
    "max_val = 4 * np.pi  # Максимальное значение для временной оси (в радианах)\n",
    "\n",
    "# Создание временной оси (массив временных меток)\n",
    "# np.linspace создает равномерно распределенные значения от min_val до max_val\n",
    "# Количество точек = длительность (сек) × частота дискретизации (Гц)\n",
    "t = np.linspace(min_val, max_val, duration * sampling_freq)\n",
    "\n",
    "# Генерация чистого синусоидального сигнала с заданной частотой\n",
    "# Формула: A * sin(2π * f * t), где A=1 (амплитуда), f - частота тона\n",
    "signal = np.sin(2 * np.pi * tone_freq * t)\n",
    "\n",
    "# Добавление случайного шума к сигналу для создания более реалистичного звука\n",
    "# np.random.rand генерирует случайные числа от 0 до 1 в форме массива\n",
    "# 0.5 - коэффициент, определяющий уровень шума относительно сигнала\n",
    "noise = 0.5 * np.random.rand(duration * sampling_freq)\n",
    "signal += noise  # Добавляем шум к исходному сигналу\n",
    "\n",
    "# Подготовка сигнала для записи в 16-битный WAV файл\n",
    "scaling_factor = np.power(2, 15) - 1  # Максимальное значение для 16-битного знакового целого (32767)\n",
    "signal_normalized = signal / np.max(np.abs(signal))  # Нормализация к диапазону [-1, 1]\n",
    "signal_scaled = np.int16(signal_normalized * scaling_factor)  # Преобразование к 16-битному формату\n",
    "\n",
    "# Запись сгенерированного аудиосигнала в WAV файл\n",
    "write(output_file, sampling_freq, signal_scaled)\n",
    "\n",
    "# Для визуализации берем только первые 200 отсчетов сигнала\n",
    "signal = signal[:200]\n",
    "\n",
    "# Создание временной оси в миллисекундах для графика\n",
    "# arange создает массив индексов от 0 до 199\n",
    "# Каждый индекс преобразуется во время: (индекс / частота дискретизации) * 1000\n",
    "time_axis = 1000 * np.arange(0, len(signal), 1) / float(sampling_freq)\n",
    "\n",
    "# Построение графика сгенерированного аудиосигнала\n",
    "plt.plot(time_axis, signal, color='black')  # Черная линия сигнала\n",
    "plt.xlabel('Время (миллисекунды)')  # Подпись оси X\n",
    "plt.ylabel('Амплитуда')  # Подпись оси Y\n",
    "plt.title('Сгенерированный аудиосигнал')  # Заголовок графика\n",
    "plt.show()  # Отображение графика"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7327b07",
   "metadata": {},
   "source": [
    "## Извлечение речевых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97863195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Импорт библиотеки для работы с массивами и математическими операциями\n",
    "import matplotlib.pyplot as plt  # Импорт библиотеки для построения графиков\n",
    "from scipy.io import wavfile  # Импорт функции для чтения WAV файлов\n",
    "from python_speech_features import mfcc, logfbank  # Импорт функций для извлечения аудио-признаков\n",
    "\n",
    "# Чтение WAV файла: функция возвращает частоту дискретизации и аудиосигнал\n",
    "sampling_freq, signal = wavfile.read('dataset/random_sound1.wav')\n",
    "\n",
    "# Ограничиваем сигнал первыми 10000 отсчетами для анализа (примерно 0.23 сек при 44.1 кГц)\n",
    "# Это ускоряет обработку и визуализацию\n",
    "signal = signal[:10000]\n",
    "\n",
    "# Извлечение MFCC (Mel-frequency cepstral coefficients - мел-кепстральные коэффициенты)\n",
    "# MFCC - популярные признаки для распознавания речи, моделирующие восприятие звука человеком\n",
    "features_mfcc = mfcc(signal, sampling_freq)\n",
    "\n",
    "# Вывод информации о MFCC признаках\n",
    "print('\\nMFCC:\\nКоличество окон =', features_mfcc.shape[0])  # Количество временных окон\n",
    "print('Длина каждого признака =', features_mfcc.shape[1])  # Количество MFCC коэффициентов (обычно 13)\n",
    "\n",
    "# Транспонирование матрицы MFCC для визуализации (временная ось по горизонтали, коэффициенты по вертикали)\n",
    "features_mfcc = features_mfcc.T\n",
    "plt.matshow(features_mfcc)  # Построение тепловой карты MFCC\n",
    "plt.title('MFCC')  # Заголовок графика\n",
    "\n",
    "# Извлечение признаков фильтр-банка (log mel-filter bank energies)\n",
    "# Логарифмическая энергия полос мел-фильтров - более простые признаки, чем MFCC\n",
    "features_fb = logfbank(signal, sampling_freq)\n",
    "\n",
    "# Вывод информации о признаках фильтр-банка\n",
    "print('\\nФильтр-банк:\\nКоличество окон =', features_fb.shape[0])  # Количество временных окон\n",
    "print('Длина каждого признака =', features_fb.shape[1])  # Количество фильтров в банке (обычно 26)\n",
    "\n",
    "# Транспонирование матрицы фильтр-банка для визуализации\n",
    "features_fb = features_fb.T\n",
    "plt.matshow(features_fb)  # Построение тепловой карты фильтр-банка\n",
    "plt.title('Фильтр-банк')  # Заголовок графика\n",
    "\n",
    "plt.show()  # Отображение обоих графиков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b6a8a",
   "metadata": {},
   "source": [
    "## Преобразование аудиосигналов в частотные интервалы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20e98bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Импорт библиотеки для работы с массивами и математических операций\n",
    "import matplotlib.pyplot as plt  # Импорт библиотеки для построения графиков\n",
    "from scipy.io import wavfile  # Импорт функции для чтения WAV файлов\n",
    "\n",
    "# Чтение WAV файла: функция возвращает частоту дискретизации и аудиосигнал\n",
    "sampling_freq, signal = wavfile.read('dataset/spoken_word.wav')\n",
    "\n",
    "# Нормализация сигнала: приведение значений к диапазону [-1, 1] для 16-битного аудио\n",
    "# 2^15 = 32768 (максимальное значение для 16-битного знакового целого)\n",
    "signal = signal / np.power(2, 15) \n",
    "\n",
    "# Определение длины сигнала (количество отсчетов)\n",
    "len_signal = len(signal)\n",
    "\n",
    "# Вычисление половины длины сигнала (округление вверх)\n",
    "# Для быстрого преобразования Фурье достаточно рассматривать половину спектра\n",
    "# (из-за симметрии для вещественных сигналов)\n",
    "len_half = np.ceil((len_signal + 1) / 2.0).astype(int)\n",
    "\n",
    "# Выполнение быстрого преобразования Фурье (FFT) для перехода из временной области в частотную\n",
    "# Результат - комплексные числа, представляющие амплитуду и фазу частотных составляющих\n",
    "freq_signal = np.fft.fft(signal)\n",
    "\n",
    "# Извлечение амплитудного спектра (модуль комплексных чисел)\n",
    "# Берём только первую половину (положительные частоты) и нормируем на длину сигнала\n",
    "freq_signal = abs(freq_signal[0:len_half]) / len_signal\n",
    "\n",
    "# Возведение в квадрат для получения мощности (спектральная плотность мощности)\n",
    "# Мощность пропорциональна квадрату амплитуды\n",
    "freq_signal **= 2\n",
    "\n",
    "# Длина массива спектра мощности\n",
    "len_fts = len(freq_signal)\n",
    "\n",
    "# Корректировка мощности с учетом симметрии БПФ:\n",
    "# Для нечетного числа точек удваиваем все значения, кроме первого (нулевой частоты)\n",
    "# Для четного числа точек удваиваем все значения, кроме первого и последнего\n",
    "# Это необходимо, так как мы взяли только половину спектра\n",
    "if len_signal % 2:\n",
    "    freq_signal[1:len_fts] *= 2\n",
    "else:\n",
    "    freq_signal[1:len_fts-1] *= 2\n",
    "\n",
    "# Преобразование мощности в децибелы (логарифмическая шкала)\n",
    "# 10 * log10(x) - стандартная формула для перевода мощности в дБ\n",
    "signal_power = 10 * np.log10(freq_signal)\n",
    "\n",
    "# Создание частотной оси в кГц для построения графика\n",
    "# Каждая точка спектра соответствует определенной частоте:\n",
    "# частота = (индекс * частота_дискретизации) / длина_сигнала\n",
    "x_axis = np.arange(0, len_half, 1) * (sampling_freq / len_signal) / 1000.0\n",
    "\n",
    "# Построение графика спектра мощности\n",
    "plt.figure()\n",
    "plt.plot(x_axis, signal_power, color='black')  # Черный график зависимости мощности от частоты\n",
    "plt.xlabel('Частота (кГц)')  # Подпись оси X (частота в килогерцах)\n",
    "plt.ylabel('Мощность сигнала (дБ)')  # Подпись оси Y (мощность в децибелах)\n",
    "plt.show()  # Отображение графика"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f55cfe",
   "metadata": {},
   "source": [
    "## Синтезирование звуков для генерации музыки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6238ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  # Импорт модуля для работы с JSON файлами (чтение/запись)\n",
    "import numpy as np  # Импорт библиотеки для работы с массивами и математическими операциями\n",
    "import matplotlib.pyplot as plt  # Импорт библиотеки для построения графиков\n",
    "from scipy.io.wavfile import write  # Импорт функции записи WAV файлов\n",
    "\n",
    "def tone_synthesizer(freq, duration, amplitude=1.0, sampling_freq=44100):\n",
    "    \"\"\"\n",
    "    Синтезатор тона: генерирует синусоидальный сигнал заданной частоты.\n",
    "    \n",
    "    Args:\n",
    "        freq: Частота тона в Герцах (Гц)\n",
    "        duration: Длительность тона в секундах\n",
    "        amplitude: Амплитуда сигнала (по умолчанию 1.0)\n",
    "        sampling_freq: Частота дискретизации (по умолчанию 44100 Гц)\n",
    "        \n",
    "    Returns:\n",
    "        Аудиосигнал в формате 16-битного целого числа\n",
    "    \"\"\"\n",
    "    # Вычисление количества отсчетов = длительность × частота дискретизации\n",
    "    num_samples = int(duration * sampling_freq)\n",
    "    \n",
    "    # Создание временной оси от 0 до duration с равномерным шагом\n",
    "    time_axis = np.linspace(0, duration, num_samples)\n",
    "\n",
    "    # Генерация синусоидального сигнала: A × sin(2π × f × t)\n",
    "    signal = amplitude * np.sin(2 * np.pi * freq * time_axis)\n",
    "\n",
    "    # Преобразование сигнала в 16-битный целочисленный формат для записи в WAV\n",
    "    return signal.astype(np.int16) \n",
    "\n",
    "if __name__=='__main__':\n",
    "    # Имена выходных файлов для одиночного тона и последовательности тонов\n",
    "    file_tone_single = 'dataset/generated_tone_single.wav'\n",
    "    file_tone_sequence = 'dataset/generated_tone_sequence.wav'\n",
    "\n",
    "    # Имя JSON файла с соответствием нот и частот\n",
    "    mapping_file = 'dataset/tone_mapping.json'\n",
    "\n",
    "    # Загрузка таблицы соответствия нот и частот из JSON файла\n",
    "    try:\n",
    "        with open(mapping_file, 'r') as f:\n",
    "            tone_map = json.loads(f.read())  # Чтение и парсинг JSON\n",
    "    except FileNotFoundError:\n",
    "        # Если файл не найден, создаем стандартное соответствие нот и частот\n",
    "        print(f\"Файл {mapping_file} не найден. Создаю его...\")\n",
    "        # Частоты для нот первой октавы (в Герцах):\n",
    "        tone_map = {\n",
    "            'C': 261.63,  # До\n",
    "            'D': 293.66,  # Ре\n",
    "            'E': 329.63,  # Ми\n",
    "            'F': 349.23,  # Фа\n",
    "            'G': 392.00,  # Соль\n",
    "            'A': 440.00,  # Ля\n",
    "            'B': 493.88   # Си\n",
    "        }\n",
    "        # Сохранение таблицы в JSON файл для последующего использования\n",
    "        with open(mapping_file, 'w') as f:\n",
    "            json.dump(tone_map, f)\n",
    "        print(f\"Файл {mapping_file} создан.\")\n",
    "\n",
    "    # Параметры для генерации одиночного тона\n",
    "    tone_name = 'F'  # Нота Фа\n",
    "    duration = 3     # Длительность 3 секунды\n",
    "    amplitude = 12000  # Амплитуда (максимальное значение для 16-битного аудио ≈ 32768)\n",
    "    sampling_freq = 44100  # Стандартная частота дискретизации для аудио\n",
    "\n",
    "    # Получение частоты для выбранной ноты из таблицы соответствия\n",
    "    tone_freq = tone_map[tone_name]\n",
    "\n",
    "    # Генерация одиночного тона с помощью функции-синтезатора\n",
    "    synthesized_tone = tone_synthesizer(tone_freq, duration, amplitude, sampling_freq)\n",
    "\n",
    "    # Запись одиночного тона в WAV файл\n",
    "    write(file_tone_single, sampling_freq, synthesized_tone)\n",
    "\n",
    "    # Создание последовательности тонов: список кортежей (нота, длительность)\n",
    "    tone_sequence = [('G', 0.4), ('D', 0.5), ('F', 0.3), ('C', 0.6), ('A', 0.4)]\n",
    "\n",
    "    # Инициализация пустого массива для результирующего сигнала\n",
    "    signal = np.array([])\n",
    "    \n",
    "    # Генерация и объединение всех тонов из последовательности\n",
    "    for item in tone_sequence:\n",
    "        tone_name = item[0]  # Получение названия ноты\n",
    "        freq = tone_map[tone_name]  # Получение частоты ноты из таблицы\n",
    "        note_duration = item[1]  # Получение длительности ноты\n",
    "\n",
    "        # Генерация тона для текущей ноты\n",
    "        synthesized_tone = tone_synthesizer(freq, note_duration, amplitude, sampling_freq)\n",
    "\n",
    "        # Добавление сгенерированного тона к общему сигналу\n",
    "        signal = np.append(signal, synthesized_tone, axis=0)\n",
    "\n",
    "    # Запись последовательности тонов в WAV файл\n",
    "    write(file_tone_sequence, sampling_freq, signal)\n",
    "    \n",
    "    # Вывод информации о созданных файлах\n",
    "    print(f\"Создан файл: {file_tone_single}\")\n",
    "    print(f\"Создан файл: {file_tone_sequence}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
