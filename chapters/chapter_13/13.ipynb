{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abaa290c",
   "metadata": {},
   "source": [
    "# 13. Обнаружение и отслеживание объектов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da30cf2b",
   "metadata": {},
   "source": [
    "## Вычисление разности между кадрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c69d0d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "СИСТЕМА ОБНАРУЖЕНИЯ ДВИЖЕНИЯ\n",
      "==================================================\n",
      "\n",
      "1. Поиск веб-камеры...\n",
      "✓ Найдена камера с индексом 0\n",
      "\n",
      "==================================================\n",
      "Источник: Камера\n",
      "==================================================\n",
      "\n",
      "Нажмите ESC для выхода\n",
      "Нажмите SPACE для паузы\n",
      "\n",
      "\n",
      "Обработано кадров: 1046\n",
      "Программа завершена.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def frame_diff(prev_frame, cur_frame, next_frame):\n",
    "    \"\"\"Вычисляет разность между кадрами для обнаружения движения.\"\"\"\n",
    "    diff_frames_1 = cv2.absdiff(next_frame, cur_frame)\n",
    "    diff_frames_2 = cv2.absdiff(cur_frame, prev_frame)\n",
    "    result = cv2.bitwise_and(diff_frames_1, diff_frames_2)\n",
    "    \n",
    "    # Пороговая обработка\n",
    "    _, thresh = cv2.threshold(result, 30, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Морфологические операции\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    thresh = cv2.dilate(thresh, kernel, iterations=2)\n",
    "    \n",
    "    return thresh\n",
    "\n",
    "\n",
    "def process_frame(frame, scaling_factor):\n",
    "    \"\"\"Обрабатывает кадр: изменяет размер и преобразует в серый.\"\"\"\n",
    "    frame = cv2.resize(frame, None, fx=scaling_factor,\n",
    "                      fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "    return gray\n",
    "\n",
    "\n",
    "def create_synthetic_video(filename='test_video.avi', duration=10):\n",
    "    \"\"\"Создает синтетическое видео с движущимся объектом.\"\"\"\n",
    "    print(f\"Создание тестового видео '{filename}'...\")\n",
    "    \n",
    "    width, height = 640, 480\n",
    "    fps = 20\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(filename, fourcc, fps, (width, height))\n",
    "    \n",
    "    frames = duration * fps\n",
    "    \n",
    "    for i in range(frames):\n",
    "        # Создаем черный фон\n",
    "        frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Движущийся круг\n",
    "        x = int((width - 100) * (i / frames) + 50)\n",
    "        y = height // 2 + int(50 * np.sin(i * 0.1))\n",
    "        cv2.circle(frame, (x, y), 30, (255, 255, 255), -1)\n",
    "        \n",
    "        # Движущийся прямоугольник\n",
    "        rect_x = int((width - 150) * ((frames - i) / frames) + 75)\n",
    "        rect_y = height // 3\n",
    "        cv2.rectangle(frame, (rect_x, rect_y), (rect_x + 60, rect_y + 60), \n",
    "                     (200, 200, 200), -1)\n",
    "        \n",
    "        # Случайный шум (имитация движения)\n",
    "        if i % 5 == 0:\n",
    "            noise_x = np.random.randint(0, width - 50)\n",
    "            noise_y = np.random.randint(0, height - 50)\n",
    "            cv2.circle(frame, (noise_x, noise_y), 15, (150, 150, 150), -1)\n",
    "        \n",
    "        out.write(frame)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"✓ Тестовое видео создано: {filename}\")\n",
    "    return filename\n",
    "\n",
    "\n",
    "def find_camera():\n",
    "    \"\"\"Ищет доступную камеру.\"\"\"\n",
    "    for i in range(5):\n",
    "        cap = cv2.VideoCapture(i)\n",
    "        if cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            cap.release()\n",
    "            if ret and frame is not None:\n",
    "                return i\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_video_source():\n",
    "    \"\"\"Определяет источник видео: камера, файл или синтетическое видео.\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"СИСТЕМА ОБНАРУЖЕНИЯ ДВИЖЕНИЯ\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Пытаемся найти камеру\n",
    "    print(\"\\n1. Поиск веб-камеры...\")\n",
    "    camera_index = find_camera()\n",
    "    \n",
    "    if camera_index is not None:\n",
    "        print(f\"✓ Найдена камера с индексом {camera_index}\")\n",
    "        use_camera = input(\"Использовать камеру? (y/n): \").lower()\n",
    "        if use_camera == 'y':\n",
    "            return cv2.VideoCapture(camera_index), \"Камера\"\n",
    "    \n",
    "    # Проверяем наличие видеофайла\n",
    "    print(\"\\n2. Поиск видеофайлов...\")\n",
    "    video_files = [f for f in os.listdir('.') if f.endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
    "    \n",
    "    if video_files:\n",
    "        print(\"Найдены видеофайлы:\")\n",
    "        for idx, vf in enumerate(video_files):\n",
    "            print(f\"  [{idx}] {vf}\")\n",
    "        \n",
    "        choice = input(\"Введите номер файла или 'n' для создания тестового видео: \")\n",
    "        if choice.isdigit() and 0 <= int(choice) < len(video_files):\n",
    "            filename = video_files[int(choice)]\n",
    "            return cv2.VideoCapture(filename), f\"Файл: {filename}\"\n",
    "    \n",
    "    # Создаем синтетическое видео\n",
    "    print(\"\\n3. Создание тестового видео...\")\n",
    "    test_video = create_synthetic_video()\n",
    "    return cv2.VideoCapture(test_video), f\"Тестовое видео: {test_video}\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Основная функция программы.\"\"\"\n",
    "    \n",
    "    # Получаем источник видео\n",
    "    cap, source_name = get_video_source()\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"❌ Ошибка: не удалось открыть источник видео\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"Источник: {source_name}\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "    print(\"\\nНажмите ESC для выхода\")\n",
    "    print(\"Нажмите SPACE для паузы\\n\")\n",
    "    \n",
    "    scaling_factor = 0.5\n",
    "    paused = False\n",
    "    \n",
    "    # Захват первых трёх кадров\n",
    "    ret1, frame1 = cap.read()\n",
    "    ret2, frame2 = cap.read()\n",
    "    ret3, frame3 = cap.read()\n",
    "    \n",
    "    if not (ret1 and ret2 and ret3):\n",
    "        print(\"❌ Ошибка чтения кадров\")\n",
    "        cap.release()\n",
    "        return\n",
    "    \n",
    "    prev_frame = process_frame(frame1, scaling_factor)\n",
    "    cur_frame = process_frame(frame2, scaling_factor)\n",
    "    next_frame = process_frame(frame3, scaling_factor)\n",
    "    \n",
    "    frame_count = 3\n",
    "    \n",
    "    # Основной цикл\n",
    "    while True:\n",
    "        if not paused:\n",
    "            # Обнаружение движения\n",
    "            motion = frame_diff(prev_frame, cur_frame, next_frame)\n",
    "            \n",
    "            # Создаем цветную визуализацию\n",
    "            motion_colored = cv2.applyColorMap(motion, cv2.COLORMAP_JET)\n",
    "            \n",
    "            # Обновление кадров\n",
    "            prev_frame = cur_frame\n",
    "            cur_frame = next_frame\n",
    "            \n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                # Если видео закончилось, начинаем сначала\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "            \n",
    "            next_frame = process_frame(frame, scaling_factor)\n",
    "            frame_count += 1\n",
    "        \n",
    "        # Отображение\n",
    "        cv2.imshow('Motion Detection', motion)\n",
    "        cv2.imshow('Motion Heatmap', motion_colored)\n",
    "        \n",
    "        # Обработка клавиш\n",
    "        key = cv2.waitKey(30 if not paused else 0)\n",
    "        \n",
    "        if key == 27:  # ESC\n",
    "            break\n",
    "        elif key == 32:  # SPACE\n",
    "            paused = not paused\n",
    "            print(\"Пауза\" if paused else \"Возобновление\")\n",
    "    \n",
    "    print(f\"\\nОбработано кадров: {frame_count}\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Программа завершена.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c4af25",
   "metadata": {},
   "source": [
    "![Выход](pictures/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1317cabd",
   "metadata": {},
   "source": [
    "## Отслеживание объектов с помощью цветовых пространств\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a3520bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нажмите ESC для выхода\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_frame(cap, scaling_factor):\n",
    "    \"\"\"\n",
    "    Захватывает текущий кадр из веб-камеры и изменяет его размер\n",
    "    \n",
    "    Args:\n",
    "        cap: объект захвата видео\n",
    "        scaling_factor: коэффициент масштабирования\n",
    "    \n",
    "    Returns:\n",
    "        Измененный кадр\n",
    "    \"\"\"\n",
    "    # Чтение текущего кадра из объекта захвата видео\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        return None\n",
    "    \n",
    "    # Изменение размера изображения\n",
    "    frame = cv2.resize(frame, None, fx=scaling_factor,\n",
    "                      fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "    return frame\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Определение объекта захвата видео\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Проверка успешного открытия камеры\n",
    "    if not cap.isOpened():\n",
    "        print(\"Ошибка: не удалось открыть веб-камеру\")\n",
    "        exit()\n",
    "    \n",
    "    # Определение объекта вычитания фона\n",
    "    bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "    \n",
    "    # Определим количество предыдущих кадров, которые следует\n",
    "    # использовать для обучения. Этот фактор управляет скоростью\n",
    "    # обучения алгоритма. Под скоростью обучения подразумевается\n",
    "    # скорость, с которой ваша модель будет учиться распознавать\n",
    "    # фон. Чем выше значение параметра 'history', тем ниже\n",
    "    # скорость обучения.\n",
    "    history = 100\n",
    "    \n",
    "    # Определение скорости обучения\n",
    "    learning_rate = 1.0 / history\n",
    "    \n",
    "    print(\"Нажмите ESC для выхода\")\n",
    "    \n",
    "    # Чтение кадров из веб-камеры до тех пор,\n",
    "    # пока пользователь не нажмёт клавишу <Esc>\n",
    "    while True:\n",
    "        # Захват текущего кадра\n",
    "        frame = get_frame(cap, 0.5)\n",
    "        \n",
    "        if frame is None:\n",
    "            print(\"Ошибка: не удалось захватить кадр\")\n",
    "            break\n",
    "        \n",
    "        # Вычисление маски\n",
    "        mask = bg_subtractor.apply(frame, learningRate=learning_rate)\n",
    "        \n",
    "        # Преобразование изображения из градаций серого в пространство RGB\n",
    "        mask_rgb = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # Вывод изображений\n",
    "        cv2.imshow('Input', frame)\n",
    "        cv2.imshow('Output', mask_rgb & frame)\n",
    "        \n",
    "        # Проверка того, не нажал ли пользователь клавишу <Esc>\n",
    "        c = cv2.waitKey(10)\n",
    "        if c == 27:\n",
    "            break\n",
    "    \n",
    "    # Сброс объекта захвата видео\n",
    "    cap.release()\n",
    "    \n",
    "    # Закрытие всех окон\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3046d56",
   "metadata": {},
   "source": [
    "![Выход](pictures/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a40846b",
   "metadata": {},
   "source": [
    "## Отслеживание объектов путём вычитания фоновых изображений\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b331da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запуск вычитания фона...\n",
      "Оставайтесь неподвижными несколько секунд для обучения модели\n",
      "Затем начните двигаться, чтобы увидеть эффект\n",
      "Нажмите ESC для выхода\n",
      "Программа завершена\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_frame(cap, scaling_factor):\n",
    "    \"\"\"\n",
    "    Захватывает текущий кадр из веб-камеры и изменяет его размер\n",
    "    \n",
    "    Параметры:\n",
    "        cap: объект захвата видео\n",
    "        scaling_factor: коэффициент масштабирования\n",
    "    \n",
    "    Возвращает:\n",
    "        frame: обработанный кадр\n",
    "    \"\"\"\n",
    "    # Чтение текущего кадра из объекта захвата видео\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        return None\n",
    "    \n",
    "    # Изменение размера изображения\n",
    "    frame = cv2.resize(frame, None, fx=scaling_factor,\n",
    "                      fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Определение объекта захвата видео\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Проверка успешного открытия камеры\n",
    "    if not cap.isOpened():\n",
    "        print(\"Ошибка: не удалось открыть веб-камеру\")\n",
    "        exit()\n",
    "    \n",
    "    # Определение объекта вычитания фона\n",
    "    # MOG2 (Mixture of Gaussians) - современный алгоритм вычитания фона\n",
    "    bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "    \n",
    "    # Определение количества предыдущих кадров, которые следует\n",
    "    # использовать для обучения. Этот фактор управляет скоростью\n",
    "    # обучения алгоритма. Под скоростью обучения подразумевается\n",
    "    # скорость, с которой ваша модель будет учиться распознавать\n",
    "    # фон. Чем выше значение параметра 'history', тем ниже\n",
    "    # скорость обучения. Вы можете поэкспериментировать с этим\n",
    "    # значением, чтобы увидеть, как оно влияет на результат.\n",
    "    history = 100\n",
    "    \n",
    "    # Определение скорости обучения\n",
    "    learning_rate = 1.0 / history\n",
    "    \n",
    "    print(\"Запуск вычитания фона...\")\n",
    "    print(\"Оставайтесь неподвижными несколько секунд для обучения модели\")\n",
    "    print(\"Затем начните двигаться, чтобы увидеть эффект\")\n",
    "    print(\"Нажмите ESC для выхода\")\n",
    "    \n",
    "    # Чтение кадров из веб-камеры до тех пор,\n",
    "    # пока пользователь не нажмёт клавишу <Esc>\n",
    "    while True:\n",
    "        # Захват текущего кадра\n",
    "        frame = get_frame(cap, 0.5)\n",
    "        \n",
    "        if frame is None:\n",
    "            print(\"Ошибка: не удалось получить кадр\")\n",
    "            break\n",
    "        \n",
    "        # Вычисление маски с использованием алгоритма вычитания фона\n",
    "        mask = bg_subtractor.apply(frame, learningRate=learning_rate)\n",
    "        \n",
    "        # Преобразование маски из градаций серого в RGB\n",
    "        # для корректного применения побитового И\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # Применение маски к исходному изображению\n",
    "        # для выделения движущихся объектов\n",
    "        output = mask & frame\n",
    "        \n",
    "        # Вывод изображений\n",
    "        cv2.imshow('Input', frame)\n",
    "        cv2.imshow('Motion mask', mask)\n",
    "        cv2.imshow('Output', output)\n",
    "        \n",
    "        # Проверка того, не нажал ли пользователь клавишу <Esc>\n",
    "        c = cv2.waitKey(10)\n",
    "        if c == 27:  # ESC\n",
    "            break\n",
    "    \n",
    "    # Сброс объекта захвата видео\n",
    "    cap.release()\n",
    "    \n",
    "    # Закрытие всех окон\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(\"Программа завершена\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a53ec4",
   "metadata": {},
   "source": [
    "![Выход](pictures/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f162ed77",
   "metadata": {},
   "source": [
    "## Создание интерактивного трекера объектов с помощью алгоритма CAMShift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "856300ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выделите объект для отслеживания мышью\n",
      "Нажмите ESC для выхода\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Определение класса, содержащего всю функциональность,\n",
    "# необходимую для отслеживания объектов\n",
    "class ObjectTracker(object):\n",
    "    def __init__(self, scaling_factor=0.5):\n",
    "        # Инициализация объекта захвата видео\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        # Проверка успешного открытия камеры\n",
    "        if not self.cap.isOpened():\n",
    "            print(\"Ошибка: не удалось открыть веб-камеру\")\n",
    "            exit()\n",
    "        \n",
    "        # Захват кадра из веб-камеры\n",
    "        ret, self.frame = self.cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Ошибка: не удалось захватить кадр\")\n",
    "            exit()\n",
    "        \n",
    "        # Масштабный множитель для захваченного изображения\n",
    "        self.scaling_factor = scaling_factor\n",
    "        \n",
    "        # Изменение размера изображения\n",
    "        self.frame = cv2.resize(self.frame, None, \n",
    "                               fx=self.scaling_factor,\n",
    "                               fy=self.scaling_factor,\n",
    "                               interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Создание окна для отображения кадра\n",
    "        cv2.namedWindow('Object Tracker')\n",
    "        \n",
    "        # Установка функции обратного вызова, отслеживающей события мыши\n",
    "        cv2.setMouseCallback('Object Tracker', self.mouse_event)\n",
    "        \n",
    "        # Инициализация переменной, связанной с ограниченным\n",
    "        # прямоугольником выбранной области\n",
    "        self.selection = None\n",
    "        \n",
    "        # Инициализация переменной, связанной с начальной позицией\n",
    "        self.drag_start = None\n",
    "        \n",
    "        # Инициализация переменной, связанной с состоянием отслеживания\n",
    "        self.tracking_state = 0\n",
    "    \n",
    "    # Определение метода для отслеживания событий мыши\n",
    "    def mouse_event(self, event, x, y, flags, param):\n",
    "        # Преобразование координат X и Y в 16-битовые целые числа NumPy\n",
    "        x, y = np.int16([x, y])\n",
    "        \n",
    "        # Проверка нажатия кнопки мыши\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.drag_start = (x, y)\n",
    "            self.tracking_state = 0\n",
    "        \n",
    "        # Проверка того, не начал ли пользователь выделять область\n",
    "        if self.drag_start:\n",
    "            if flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "                # Извлечение размеров кадра\n",
    "                h, w = self.frame.shape[:2]\n",
    "                \n",
    "                # Получение начальной позиции\n",
    "                xi, yi = self.drag_start\n",
    "                \n",
    "                # Получение максимальной и минимальной координаты\n",
    "                x0, y0 = np.maximum(0, np.minimum([xi, yi], [x, y]))\n",
    "                x1, y1 = np.minimum([w, h], np.maximum([xi, yi], [x, y]))\n",
    "                \n",
    "                # Сброс переменной selection\n",
    "                self.selection = None\n",
    "                \n",
    "                # Завершение выделения прямоугольной области\n",
    "                if x1 - x0 > 0 and y1 - y0 > 0:\n",
    "                    self.selection = (x0, y0, x1, y1)\n",
    "            else:\n",
    "                # Если выделение завершено, начать отслеживание\n",
    "                self.drag_start = None\n",
    "                if self.selection is not None:\n",
    "                    self.tracking_state = 1\n",
    "    \n",
    "    # Метод, начинающий отслеживание объекта\n",
    "    def start_tracking(self):\n",
    "        print(\"Выделите объект для отслеживания мышью\")\n",
    "        print(\"Нажмите ESC для выхода\")\n",
    "        \n",
    "        # Итерируем до тех пор, пока пользователь не нажмёт клавишу <Esc>\n",
    "        while True:\n",
    "            # Захват кадра из веб-камеры\n",
    "            ret, self.frame = self.cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                print(\"Ошибка: не удалось захватить кадр\")\n",
    "                break\n",
    "            \n",
    "            # Изменение размера входного кадра\n",
    "            self.frame = cv2.resize(self.frame, None,\n",
    "                                   fx=self.scaling_factor,\n",
    "                                   fy=self.scaling_factor,\n",
    "                                   interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "            # Создание копии кадра\n",
    "            vis = self.frame.copy()\n",
    "            \n",
    "            # Преобразование кадра в цветное пространство HSV\n",
    "            hsv = cv2.cvtColor(self.frame, cv2.COLOR_BGR2HSV)\n",
    "            \n",
    "            # Создание маски на основании предварительно установленных пороговых значений\n",
    "            mask = cv2.inRange(hsv, np.array((0., 60., 32.)),\n",
    "                              np.array((180., 255., 255.)))\n",
    "            \n",
    "            # Проверка выделения пользователем области\n",
    "            if self.selection:\n",
    "                # Извлечение координат выделенного прямоугольника\n",
    "                x0, y0, x1, y1 = self.selection\n",
    "                \n",
    "                # Извлечение окна отслеживания\n",
    "                self.track_window = (x0, y0, x1 - x0, y1 - y0)\n",
    "                \n",
    "                # Извлечение интересующей нас области\n",
    "                hsv_roi = hsv[y0:y1, x0:x1]\n",
    "                mask_roi = mask[y0:y1, x0:x1]\n",
    "                \n",
    "                # Вычисление гистограммы интересующей нас области\n",
    "                # HSV-изображения с использованием маски\n",
    "                hist = cv2.calcHist([hsv_roi], [0], mask_roi, [16], [0, 180])\n",
    "                \n",
    "                # Нормализация и переформирование гистограммы\n",
    "                cv2.normalize(hist, hist, 0, 255, cv2.NORM_MINMAX)\n",
    "                self.hist = hist.reshape(-1)\n",
    "                \n",
    "                # Извлечение интересующей нас области из кадра\n",
    "                vis_roi = vis[y0:y1, x0:x1]\n",
    "                \n",
    "                # Вычисление негативного изображения (исключительно в целях отображения)\n",
    "                cv2.bitwise_not(vis_roi, vis_roi)\n",
    "                vis[mask == 0] = 0\n",
    "            \n",
    "            # Проверка того, находится ли система в состоянии \"отслеживание\"\n",
    "            if self.tracking_state == 1:\n",
    "                # Сброс переменной selection\n",
    "                self.selection = None\n",
    "                \n",
    "                # Вычисление проекции гистограммы на просвет\n",
    "                hsv_backproj = cv2.calcBackProject([hsv], [0], self.hist, [0, 180], 1)\n",
    "                \n",
    "                # Вычисление результата применения операции побитового И\n",
    "                # к проекции гистограммы на просвет и маске\n",
    "                hsv_backproj &= mask\n",
    "                \n",
    "                # Определение критерия для прекращения работы трекера\n",
    "                term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "                \n",
    "                # Применение алгоритма CAMShift к 'hsv_backproj'\n",
    "                track_box, self.track_window = cv2.CamShift(hsv_backproj,\n",
    "                                                            self.track_window,\n",
    "                                                            term_crit)\n",
    "                \n",
    "                # Вычерчивание эллипса вокруг объекта\n",
    "                cv2.ellipse(vis, track_box, (0, 255, 0), 2)\n",
    "            \n",
    "            # Отображение живого видео\n",
    "            cv2.imshow('Object Tracker', vis)\n",
    "            \n",
    "            # Прекратить, если пользователь нажал клавишу <Esc>\n",
    "            c = cv2.waitKey(5)\n",
    "            if c == 27:\n",
    "                break\n",
    "        \n",
    "        # Освобождение ресурсов\n",
    "        self.cap.release()\n",
    "        \n",
    "        # Закрытие всех окон\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Запуск трекера\n",
    "    ObjectTracker().start_tracking()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d1499",
   "metadata": {},
   "source": [
    "![Выход](pictures/4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936399f",
   "metadata": {},
   "source": [
    "## Отслеживание объектов с использованием оптических потоков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae826957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отслеживание началось. Нажмите ESC для выхода\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Определим функцию для отслеживания объекта\n",
    "def start_tracking():\n",
    "    # Инициализация объекта захвата видео\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Проверка успешного открытия камеры\n",
    "    if not cap.isOpened():\n",
    "        print(\"Ошибка: не удалось открыть веб-камеру\")\n",
    "        return\n",
    "    \n",
    "    # Определение масштабного множителя для кадров\n",
    "    scaling_factor = 0.5\n",
    "    \n",
    "    # Количество отслеживаемых кадров\n",
    "    num_frames_to_track = 5\n",
    "    \n",
    "    # Шаг пропуска\n",
    "    num_frames_jump = 2\n",
    "    \n",
    "    # Инициализация переменных\n",
    "    tracking_paths = []\n",
    "    frame_index = 0\n",
    "    \n",
    "    # Определение параметров отслеживания\n",
    "    tracking_params = dict(\n",
    "        winSize=(11, 11),\n",
    "        maxLevel=2,\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "    )\n",
    "    \n",
    "    print(\"Отслеживание началось. Нажмите ESC для выхода\")\n",
    "    \n",
    "    # Итерирование до тех пор, пока пользователь не нажмёт клавишу <Esc>\n",
    "    while True:\n",
    "        # Захват текущего кадра\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Ошибка: не удалось захватить кадр\")\n",
    "            break\n",
    "        \n",
    "        # Изменение размеров кадра\n",
    "        frame = cv2.resize(frame, None, \n",
    "                          fx=scaling_factor,\n",
    "                          fy=scaling_factor,\n",
    "                          interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Преобразование в градации серого\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Создание копии кадра\n",
    "        output_img = frame.copy()\n",
    "        \n",
    "        # Проверим, превышает ли длина отслеживаемых путей нуль\n",
    "        if len(tracking_paths) > 0:\n",
    "            # Получение изображений\n",
    "            prev_img, current_img = prev_gray, frame_gray\n",
    "            \n",
    "            # Организация особых точек\n",
    "            feature_points_0 = np.float32([tp[-1] for tp in tracking_paths]).reshape(-1, 1, 2)\n",
    "            \n",
    "            # Вычисление оптического потока\n",
    "            feature_points_1, _, _ = cv2.calcOpticalFlowPyrLK(\n",
    "                prev_img, current_img, feature_points_0,\n",
    "                None, **tracking_params\n",
    "            )\n",
    "            \n",
    "            # Вычисление обратного оптического потока\n",
    "            feature_points_0_rev, _, _ = cv2.calcOpticalFlowPyrLK(\n",
    "                current_img, prev_img, feature_points_1,\n",
    "                None, **tracking_params\n",
    "            )\n",
    "            \n",
    "            # Вычисление разности между прямым и обратным оптическими потоками\n",
    "            diff_feature_points = abs(feature_points_0 - feature_points_0_rev).reshape(-1, 2).max(-1)\n",
    "            \n",
    "            # Извлечение подходящих точек\n",
    "            good_points = diff_feature_points < 1\n",
    "            \n",
    "            # Инициализация переменной\n",
    "            new_tracking_paths = []\n",
    "            \n",
    "            # Итерации по всем подходящим особым точкам\n",
    "            for tp, (x, y), good_points_flag in zip(\n",
    "                tracking_paths,\n",
    "                feature_points_1.reshape(-1, 2),\n",
    "                good_points\n",
    "            ):\n",
    "                # Продолжение, если флаг не равен true\n",
    "                if not good_points_flag:\n",
    "                    continue\n",
    "                \n",
    "                # Присоединение координат X и Y и проверка того,\n",
    "                # не превышает ли длина списка пороговое значение\n",
    "                tp.append((x, y))\n",
    "                if len(tp) > num_frames_to_track:\n",
    "                    del tp[0]\n",
    "                \n",
    "                new_tracking_paths.append(tp)\n",
    "                \n",
    "                # Вычерчивание окружности вокруг особых точек\n",
    "                cv2.circle(output_img, (int(x), int(y)), 3, (0, 255, 0), -1)\n",
    "            \n",
    "            # Обновление путей отслеживания\n",
    "            tracking_paths = new_tracking_paths\n",
    "            \n",
    "            # Вычерчивание линий\n",
    "            cv2.polylines(output_img, [np.int32(tp) for tp in tracking_paths],\n",
    "                         False, (0, 150, 0))\n",
    "        \n",
    "        # Вход в блок 'if' после пропуска подходящего количества кадров\n",
    "        if not frame_index % num_frames_jump:\n",
    "            # Создание маски и вычерчивание окружностей\n",
    "            mask = np.zeros_like(frame_gray)\n",
    "            mask[:] = 255\n",
    "            \n",
    "            for x, y in [np.int32(tp[-1]) for tp in tracking_paths]:\n",
    "                cv2.circle(mask, (x, y), 6, 0, -1)\n",
    "            \n",
    "            # Вычисление подходящих признаков для отслеживания\n",
    "            feature_points = cv2.goodFeaturesToTrack(\n",
    "                frame_gray,\n",
    "                mask=mask,\n",
    "                maxCorners=500,\n",
    "                qualityLevel=0.3,\n",
    "                minDistance=7,\n",
    "                blockSize=7\n",
    "            )\n",
    "            \n",
    "            # Проверка существования особых точек; если они\n",
    "            # существуют, присоединить их к путям отслеживания\n",
    "            if feature_points is not None:\n",
    "                for x, y in np.float32(feature_points).reshape(-1, 2):\n",
    "                    tracking_paths.append([(x, y)])\n",
    "        \n",
    "        # Обновление переменных\n",
    "        frame_index += 1\n",
    "        prev_gray = frame_gray\n",
    "        \n",
    "        # Отображение результата\n",
    "        cv2.imshow('Input', output_img)\n",
    "        \n",
    "        # Проверка того, не нажал ли пользователь клавишу <Esc>\n",
    "        c = cv2.waitKey(1)\n",
    "        if c == 27:\n",
    "            break\n",
    "    \n",
    "    # Освобождение ресурсов\n",
    "    cap.release()\n",
    "    \n",
    "    # Закрытие всех окон\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Запуск трекера\n",
    "    start_tracking()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1f2500",
   "metadata": {},
   "source": [
    "![Вывод](pictures/5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48af25",
   "metadata": {},
   "source": [
    "## Обнаружение и отслеживание лиц\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6241a292",
   "metadata": {},
   "source": [
    "### Использование каскадов Хаара для обнаружения лиц\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b71f35e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@3025.198] global persistence.cpp:531 open Can't open file: 'haar_cascade_files/haarcascade_frontalface_default.xml' in read mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Детектор лиц запущен. Нажмите ESC для выхода\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка файла каскада Хаара\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    'haar_cascade_files/haarcascade_frontalface_default.xml'\n",
    ")\n",
    "\n",
    "# Если файл не найден локально, попробуйте использовать встроенный путь OpenCV\n",
    "if face_cascade.empty():\n",
    "    face_cascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "    )\n",
    "\n",
    "# Проверка корректности загрузки файла каскада\n",
    "if face_cascade.empty():\n",
    "    raise IOError('Unable to load the face cascade classifier xml file')\n",
    "\n",
    "# Инициализируем объект захвата видео\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Проверка успешного открытия камеры\n",
    "if not cap.isOpened():\n",
    "    print(\"Ошибка: не удалось открыть веб-камеру\")\n",
    "    exit()\n",
    "\n",
    "# Определение масштабного множителя\n",
    "scaling_factor = 0.5\n",
    "\n",
    "print(\"Детектор лиц запущен. Нажмите ESC для выхода\")\n",
    "\n",
    "# Итерируем до тех пор, пока пользователь не нажмёт клавишу <Esc>\n",
    "while True:\n",
    "    # Захват текущего кадра\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Ошибка: не удалось захватить кадр\")\n",
    "        break\n",
    "    \n",
    "    # Изменение размера кадра\n",
    "    frame = cv2.resize(frame, None,\n",
    "                      fx=scaling_factor,\n",
    "                      fy=scaling_factor,\n",
    "                      interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Преобразование в градации серого\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Выполнение детектора лиц для изображения в градациях серого\n",
    "    face_rects = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # Вычерчивание прямоугольника вокруг лица\n",
    "    for (x, y, w, h) in face_rects:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "    \n",
    "    # Отображение результата\n",
    "    cv2.imshow('Face detection', frame)\n",
    "    \n",
    "    # Проверка того, не нажал ли пользователь клавишу <Esc>\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break\n",
    "\n",
    "# Освобождение объекта захвата видео\n",
    "cap.release()\n",
    "\n",
    "# Закрытие всех окон\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3715525",
   "metadata": {},
   "source": [
    "![Вывод](pictures/6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b26e190",
   "metadata": {},
   "source": [
    "### Отслеживание глаз и определение координат взора\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee7658ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@3094.480] global persistence.cpp:531 open Can't open file: 'haar_cascade_files/haarcascade_frontalface_default.xml' in read mode\n",
      "[ERROR:0@3094.480] global persistence.cpp:531 open Can't open file: 'haar_cascade_files/haarcascade_eye.xml' in read mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Детектор глаз запущен. Нажмите ESC для выхода\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка файлов каскадов Хаара для лиц и глаз\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    'haar_cascade_files/haarcascade_frontalface_default.xml'\n",
    ")\n",
    "eye_cascade = cv2.CascadeClassifier(\n",
    "    'haar_cascade_files/haarcascade_eye.xml'\n",
    ")\n",
    "\n",
    "# Если файлы не найдены локально, попробуйте использовать встроенные пути OpenCV\n",
    "if face_cascade.empty():\n",
    "    face_cascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "    )\n",
    "\n",
    "if eye_cascade.empty():\n",
    "    eye_cascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + 'haarcascade_eye.xml'\n",
    "    )\n",
    "\n",
    "# Проверка корректности загрузки файла каскада лица\n",
    "if face_cascade.empty():\n",
    "    raise IOError('Unable to load the face cascade classifier xml file')\n",
    "\n",
    "# Проверка корректности загрузки файла каскада глаз\n",
    "if eye_cascade.empty():\n",
    "    raise IOError('Unable to load the eye cascade classifier xml file')\n",
    "\n",
    "# Инициализация объекта захвата видео\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Проверка успешного открытия камеры\n",
    "if not cap.isOpened():\n",
    "    print(\"Ошибка: не удалось открыть веб-камеру\")\n",
    "    exit()\n",
    "\n",
    "# Определение масштабного множителя\n",
    "ds_factor = 0.5\n",
    "\n",
    "print(\"Детектор глаз запущен. Нажмите ESC для выхода\")\n",
    "\n",
    "# Итерируем до тех пор, пока пользователь не нажмёт клавишу 'Esc'\n",
    "while True:\n",
    "    # Захват текущего кадра\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Ошибка: не удалось захватить кадр\")\n",
    "        break\n",
    "    \n",
    "    # Изменение размера кадра\n",
    "    frame = cv2.resize(frame, None, \n",
    "                      fx=ds_factor, \n",
    "                      fy=ds_factor,\n",
    "                      interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Преобразование в градации серого\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Выполнение детектора лиц для изображения в градациях серого\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # Выполнение детектора глаз для каждого обнаруженного лица\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Извлечение интересующей нас области изображения лица\n",
    "        # в градациях серого\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        \n",
    "        # Извлечение интересующей нас области цветного изображения лица\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        \n",
    "        # Выполнение детектора глаз в интересующей нас области\n",
    "        # изображения в градациях серого\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        \n",
    "        # Вычерчивание окружностей вокруг глаз\n",
    "        for (x_eye, y_eye, w_eye, h_eye) in eyes:\n",
    "            center = (int(x_eye + 0.5 * w_eye), int(y_eye + 0.5 * h_eye))\n",
    "            radius = int(0.3 * (w_eye + h_eye))\n",
    "            color = (0, 255, 0)\n",
    "            thickness = 3\n",
    "            cv2.circle(roi_color, center, radius, color, thickness)\n",
    "    \n",
    "    # Отобразить вывод\n",
    "    cv2.imshow('Eyes detection', frame)\n",
    "    \n",
    "    # Проверка того, не нажал ли пользователь клавишу <Esc>\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break\n",
    "\n",
    "# Освобождение объекта захвата видео\n",
    "cap.release()\n",
    "\n",
    "# Закрытие всех окон\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebe3a46",
   "metadata": {},
   "source": [
    "![Вывод](pictures/7.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_data_science (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
